{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukaszSzarecki/music-source-separation/blob/develop/ml_algorithms_pl_small_size.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_-ZXprGucr3"
      },
      "source": [
        "**[PL]** W ramach tego notatnika stworzone zostały architektury modelów uczenia głębokiego, służące separacji dźwiękowej pojedynczego źródła według strategii jeden przeciw wszystkim (one-vs-all).\n",
        "Każdy z modeli był trenowany a następnie poddany ocenie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_0idXt8WDWN"
      },
      "outputs": [],
      "source": [
        "!pip install nussl\n",
        "!pip install scaper\n",
        "!pip install git+https://github.com/source-separation/tutorial\n",
        "\n",
        "import nussl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AznNYQzBWXRT"
      },
      "source": [
        "# Pobranie datasetu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mlEak9JzLRG"
      },
      "outputs": [],
      "source": [
        "from common import data, viz\n",
        "from nussl.datasets import transforms as nussl_tfm\n",
        "\n",
        "data.prepare_musdb('~/.nussl/tutorial/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD5YinbG_fFf"
      },
      "outputs": [],
      "source": [
        "song_name = \"The Long Wait - Dark Horses.stem.mp4\"\n",
        "\n",
        "signal = nussl.AudioSignal(f\"/root/.nussl/musdb18/test/{song_name}\")\n",
        "_ = signal.embed_audio()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ2sxROdA4dV"
      },
      "outputs": [],
      "source": [
        "print(\"Czas trwania utworu: {} [s]\".format(signal.signal_duration))\n",
        "print(\"Liczba próbek w sygnale: {} \".format(signal.signal_length))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34u7y1lGZR3E"
      },
      "source": [
        "# Pobranie modeli zapisanych w repozytorium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAcMr2SVopf5"
      },
      "outputs": [],
      "source": [
        "from common import utils\n",
        "from common.models import MaskInference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WYKANNqCOTp"
      },
      "outputs": [],
      "source": [
        "!git clone -b models https://github.com/LukaszSzarecki/music-source-separation.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP8iW4Uc0mWs"
      },
      "source": [
        "Modele na repozytorium:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiZmilKqxwCV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "model_dir = '/content/music-source-separation/models/'\n",
        "new_models_names = os.listdir(model_dir + 'new/')\n",
        "old_models_names = os.listdir(model_dir + 'old/')\n",
        "\n",
        "pprint(\"New trained models\")\n",
        "for m in new_models_names:\n",
        "  pprint(m)\n",
        "\n",
        "pprint(\"Old trained models\")\n",
        "for m in old_models_names:\n",
        "  pprint(m)\n",
        "\n",
        "[\"old/\" + model_name for model_name in old_models_names]\n",
        "\n",
        "old_models_paths = [\"old/\" + model_name for model_name in old_models_names]\n",
        "new_models_paths = [\"new/\" + model_name for model_name in new_models_names]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bGEAS9wy_Ka"
      },
      "source": [
        "# Separacja perkusji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn1omeFcy_Kh"
      },
      "outputs": [],
      "source": [
        "tfm = nussl_tfm.Compose([\n",
        "    # nussl_tfm.SumSources([['bass', 'drums', 'other']]), \n",
        "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
        "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
        "    nussl_tfm.ToSeparationModel(),\n",
        "])\n",
        "\n",
        "ps = ('uniform', -3, 3)\n",
        "ts = ('uniform', 0.6, 1.4)\n",
        "\n",
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "# Dane treningowe\n",
        "fg_path = \"~/.nussl/tutorial/train\"\n",
        "train_data_1 = data.on_the_fly(stft_params, transform=tfm, pitch_shift=ps, time_stretch=ts, fg_path=fg_path, num_mixtures=10000, coherent_prob=0.7)\n",
        "\n",
        "# Dane walidacyjne\n",
        "fg_path = \"~/.nussl/tutorial/valid\"\n",
        "val_data_1 = data.on_the_fly(stft_params, transform=tfm, pitch_shift=ps, time_stretch=ts, fg_path=fg_path, num_mixtures=100)\n",
        "\n",
        "# Dane testowe\n",
        "fg_path = \"~/.nussl/tutorial/test\"\n",
        "test_data_1 = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=100, coherent_prob=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DkOmZ0Hy_Ki"
      },
      "outputs": [],
      "source": [
        "print(test_data_1[0].keys())\n",
        "\n",
        "print(f\"Tensor shape of mix_magnitude {test_data_1[0]['mix_magnitude'].shape}\")\n",
        "print(f\"Tensor shape of source_magnitudes {test_data_1[0]['source_magnitudes'].shape}\")\n",
        "\n",
        "\n",
        "print(f\"Tensor shape of ideal binary mask {test_data_1[0]['ideal_binary_mask'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-2oyqSc4rLE"
      },
      "outputs": [],
      "source": [
        "mix_magnitude = train_data_1[0]['mix_magnitude']\n",
        "estimates = mix_magnitude.unsqueeze(-1)\n",
        "print(estimates.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75nEyptWy_Kj"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1RM9eNry_Kj"
      },
      "outputs": [],
      "source": [
        "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class MaskInference(nn.Module):\n",
        "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
        "                 num_layers, bidirectional, dropout, num_sources, \n",
        "                activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.amplitude_to_db = AmplitudeToDB()\n",
        "        self.input_normalization = BatchNorm(num_features)\n",
        "        self.recurrent_stack = RecurrentStack(\n",
        "            num_features * num_audio_channels, hidden_size, \n",
        "            num_layers, bool(bidirectional), dropout\n",
        "        )\n",
        "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
        "        self.embedding = Embedding(num_features, hidden_size, \n",
        "                                   num_sources, activation, \n",
        "                                   num_audio_channels)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        mix_magnitude = data # save for masking\n",
        "        \n",
        "        data = self.amplitude_to_db(mix_magnitude)\n",
        "        data = self.input_normalization(data)\n",
        "        data = self.recurrent_stack(data)\n",
        "        mask = self.embedding(data)\n",
        "        estimates = mix_magnitude.unsqueeze(-1) * mask\n",
        "        \n",
        "        output = {\n",
        "            'mask': mask,\n",
        "            'estimates': estimates\n",
        "        }\n",
        "        return output\n",
        "    \n",
        "    # Added function\n",
        "    @classmethod\n",
        "    def build(cls, num_features, num_audio_channels, hidden_size, \n",
        "              num_layers, bidirectional, dropout, num_sources, \n",
        "              activation='sigmoid'):\n",
        "        # Step 1. Register our model with nussl\n",
        "        nussl.ml.register_module(cls)\n",
        "        \n",
        "        # Step 2a: Define the building blocks.\n",
        "        modules = {\n",
        "            'model': {\n",
        "                'class': 'MaskInference',\n",
        "                'args': {\n",
        "                    'num_features': num_features,\n",
        "                    'num_audio_channels': num_audio_channels,\n",
        "                    'hidden_size': hidden_size,\n",
        "                    'num_layers': num_layers,\n",
        "                    'bidirectional': bidirectional,\n",
        "                    'dropout': dropout,\n",
        "                    'num_sources': num_sources,\n",
        "                    'activation': activation\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        \n",
        "        # Step 2b: Define the connections between input and output.\n",
        "        # Here, the mix_magnitude key is the only input to the model.\n",
        "        connections = [\n",
        "            ['model', ['mix_magnitude']]\n",
        "        ]\n",
        "        \n",
        "        # Step 2c. The model outputs a dictionary, which SeparationModel will\n",
        "        # change the keys to model:mask, model:estimates. The lines below \n",
        "        # alias model:mask to just mask, and model:estimates to estimates.\n",
        "        # This will be important later when we actually deploy our model.\n",
        "        for key in ['mask', 'estimates']:\n",
        "            modules[key] = {'class': 'Alias'}\n",
        "            connections.append([key, f'model:{key}'])\n",
        "        \n",
        "        # Step 2d. There are two outputs from our SeparationModel: estimates and mask.\n",
        "        # Then put it all together.\n",
        "        output = ['estimates', 'mask',]\n",
        "        config = {\n",
        "            'name': cls.__name__,\n",
        "            'modules': modules,\n",
        "            'connections': connections,\n",
        "            'output': output\n",
        "        }\n",
        "        # Step 3. Instantiate the model as a SeparationModel.\n",
        "        return nussl.ml.SeparationModel(config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SufXpyp_y_Kk"
      },
      "source": [
        "## Trenowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvo9VADIy_Kk"
      },
      "outputs": [],
      "source": [
        "from common import utils\n",
        "from common.models import MaskInference\n",
        "from ignite.engine import Engine\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "from ignite.engine import create_supervised_evaluator\n",
        "\n",
        "\n",
        "\n",
        "utils.logger()\n",
        "\n",
        "nf = stft_params.window_length // 2 + 1\n",
        "nac = 1\n",
        "model = MaskInference.build(nf, nac, 300, 4, True, 0.25,1, 'sigmoid')\n",
        "# model = nussl.ml.SeparationModel(config)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nussl.ml.train.loss.L1Loss()\n",
        "\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_data_1, num_workers=1, batch_size=10)\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_data_1, num_workers=1, batch_size=10)\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def train_step(engine, batch):\n",
        "    optimizer.zero_grad()\n",
        "    model.cuda()\n",
        "    output = model(batch) # forward pass\n",
        "\n",
        "    # l1_lambda = 0.00001\n",
        "    # l1_norm = sum(abs(p).sum()\n",
        "    #               for p in model.parameters())\n",
        "\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )\n",
        "    # loss = loss + l1_lambda * l1_norm\n",
        "\n",
        "    \n",
        "    loss.backward() # backwards + gradient step\n",
        "    optimizer.step()\n",
        "    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(),\n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    \n",
        "    return loss_vals\n",
        "\n",
        "def val_step(engine, batch):\n",
        "    with torch.no_grad():\n",
        "        output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(), \n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    return loss_vals\n",
        "\n",
        "# Create the engines\n",
        "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
        "    train_step, val_step, device=\"cuda\"\n",
        ")\n",
        "\n",
        "# We'll save the output relative to this notebook.\n",
        "output_folder = Path('.').absolute()\n",
        "\n",
        "# Adding handlers from nussl that print out details about model training\n",
        "# run the validation step, and save the models.\n",
        "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
        "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
        "    optimizer, train_data_1, trainer, val_dataloader, validator)\n",
        "\n",
        "\n",
        "\n",
        "# trainer = Engine(print_train_data)\n",
        "\n",
        "\n",
        "# trainer, validator = add_progress_bar_handler(trainer, validator)\n",
        "\n",
        "\n",
        "# ProgressBar().attach(trainer, output_transform=lambda x: {'batch loss': x})\n",
        "nussl.ml.train.add_progress_bar_handler(trainer,validator)\n",
        "\n",
        "trainer.run(\n",
        "    train_dataloader, \n",
        "    epoch_length=100, \n",
        "    max_epochs=30\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNSMmnrd2sFu"
      },
      "source": [
        "### Wczytanie modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RDbggxV2y4k"
      },
      "source": [
        "Ustawienie modelu po trenowaniu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtiB6KVKy_Kk"
      },
      "outputs": [],
      "source": [
        "separator_1 = nussl.separation.deep.DeepMaskEstimation(\n",
        "    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rh_vOox23TK"
      },
      "source": [
        "Pobranie modelu z repozytorium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tjv4IJjt2vNT"
      },
      "outputs": [],
      "source": [
        "selected_model = [match for match in new_models_paths if \"percussion\" in match][0]\n",
        "\n",
        "print(selected_model)\n",
        "\n",
        "separator_1 = nussl.separation.deep.DeepMaskEstimation(\n",
        "    nussl.AudioSignal(), model_path=model_dir+selected_model,\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUzzl9hPy_Kl"
      },
      "outputs": [],
      "source": [
        "from common import viz\n",
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "item = test_data_1[4]\n",
        "separator_1.audio_signal = item['mix']\n",
        "\n",
        "estimates = separator_1()\n",
        "\n",
        "viz.show_sources(estimates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUq08MpaQjyI"
      },
      "outputs": [],
      "source": [
        "viz.show_sources(item['sources'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwyn-DKgxc-u"
      },
      "source": [
        "## Ocena dzialania modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kyoLxo7mJTf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "tfm = nussl_tfm.Compose([\n",
        "    nussl_tfm.SumSources([['bass', 'vocals', 'other']]),\n",
        "])\n",
        "test_evaluation_dataset_1 = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5VW_zWmmnlm"
      },
      "outputs": [],
      "source": [
        "test_evaluation_dataset_1[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFiy7eXhmMuP"
      },
      "outputs": [],
      "source": [
        "len(test_evaluation_dataset_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq9UQke5yuys"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "output_folder = Path('.').absolute()\n",
        "\n",
        "for i in range(50):\n",
        "    item = test_evaluation_dataset_1[i]\n",
        "    separator_1.audio_signal = item['mix']\n",
        "    estimates = separator_1()\n",
        "\n",
        "    source_keys = list(item['sources'].keys())\n",
        "    estimates = {\n",
        "        'drums': estimates[0],\n",
        "        'bass+vocals+other': item['mix'] - estimates[0]\n",
        "    }\n",
        "\n",
        "    sources = [item['sources'][k] for k in source_keys]\n",
        "    estimates = [estimates[k] for k in source_keys]\n",
        "\n",
        "    evaluator = nussl.evaluation.BSSEvalScale(\n",
        "        sources, estimates, source_labels=source_keys\n",
        "    )\n",
        "    scores = evaluator.evaluate()\n",
        "    output_folder = Path(output_folder).absolute()\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "    output_file = output_folder / sources[0].file_name.replace('wav', 'json')\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(scores, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgmOcAoixhWa"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "json_files = glob.glob(f\"*drums.json\")\n",
        "df1 = nussl.evaluation.aggregate_score_files(\n",
        "    json_files, aggregator=np.nanmedian)\n",
        "nussl.evaluation.associate_metrics(separator_1.model, df1, test_evaluation_dataset_1)\n",
        "report_card_1 = nussl.evaluation.report_card(\n",
        "    df1, report_each_source=True)\n",
        "print(report_card_1)\n",
        "\n",
        "filepath_1 = Path('/content/sample_data/results/drums.csv')  \n",
        "filepath_1.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df1.to_csv(filepath_1)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM3Zx5LIVPCz"
      },
      "source": [
        "# Separacja wokalu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzQ-m4ADVPCz"
      },
      "outputs": [],
      "source": [
        "tfm = nussl_tfm.Compose([\n",
        "    # nussl_tfm.SumSources([['bass', 'drums', 'other']]), \n",
        "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
        "    nussl_tfm.IndexSources('source_magnitudes', 3),\n",
        "    nussl_tfm.ToSeparationModel(),\n",
        "])\n",
        "\n",
        "ps = ('uniform', -3, 3)\n",
        "ts = ('uniform', 0.6, 1.4)\n",
        "\n",
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "# Dane treningowe\n",
        "fg_path = \"~/.nussl/tutorial/train\"\n",
        "train_data_2 = data.on_the_fly(stft_params, transform=tfm, pitch_shift=ps, time_stretch=ts, fg_path=fg_path, num_mixtures=10000, coherent_prob=0.6)\n",
        "\n",
        "# Dane walidacyjne\n",
        "fg_path = \"~/.nussl/tutorial/valid\"\n",
        "val_data_2 = data.on_the_fly(stft_params, transform=tfm, pitch_shift=ps, time_stretch=ts, fg_path=fg_path, num_mixtures=200)\n",
        "\n",
        "# Dane testowe\n",
        "fg_path = \"~/.nussl/tutorial/test\"\n",
        "test_data_2 = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=100, coherent_prob=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5P0arhPVPCz"
      },
      "outputs": [],
      "source": [
        "print(test_data_2[0].keys())\n",
        "\n",
        "print(f\"Tensor shape of mix_magnitude {test_data_2[0]['mix_magnitude'].shape}\")\n",
        "print(f\"Tensor shape of source_magnitudes {test_data_2[0]['source_magnitudes'].shape}\")\n",
        "\n",
        "\n",
        "print(f\"Tensor shape of ideal binary mask {test_data_2[0]['ideal_binary_mask'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svfyzXFTVPCz"
      },
      "outputs": [],
      "source": [
        "mix_magnitude = train_data_2[0]['mix_magnitude']\n",
        "estimates = mix_magnitude.unsqueeze(-1)\n",
        "print(estimates.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQNveRLxVPC0"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58cb71gGVPC0"
      },
      "outputs": [],
      "source": [
        "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class MaskInference(nn.Module):\n",
        "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
        "                 num_layers, bidirectional, dropout, num_sources, \n",
        "                activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.amplitude_to_db = AmplitudeToDB()\n",
        "        self.input_normalization = BatchNorm(num_features)\n",
        "        self.recurrent_stack = RecurrentStack(\n",
        "            num_features * num_audio_channels, hidden_size, \n",
        "            num_layers, bool(bidirectional), dropout\n",
        "        )\n",
        "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
        "        self.embedding = Embedding(num_features, hidden_size, \n",
        "                                   num_sources, activation, \n",
        "                                   num_audio_channels)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        mix_magnitude = data # save for masking\n",
        "        \n",
        "        data = self.amplitude_to_db(mix_magnitude)\n",
        "        data = self.input_normalization(data)\n",
        "        data = self.recurrent_stack(data)\n",
        "        mask = self.embedding(data)\n",
        "        estimates = mix_magnitude.unsqueeze(-1) * mask\n",
        "        \n",
        "        output = {\n",
        "            'mask': mask,\n",
        "            'estimates': estimates\n",
        "        }\n",
        "        return output\n",
        "    \n",
        "    # Added function\n",
        "    @classmethod\n",
        "    def build(cls, num_features, num_audio_channels, hidden_size, \n",
        "              num_layers, bidirectional, dropout, num_sources, \n",
        "              activation='sigmoid'):\n",
        "        # Step 1. Register our model with nussl\n",
        "        nussl.ml.register_module(cls)\n",
        "        \n",
        "        # Step 2a: Define the building blocks.\n",
        "        modules = {\n",
        "            'model': {\n",
        "                'class': 'MaskInference',\n",
        "                'args': {\n",
        "                    'num_features': num_features,\n",
        "                    'num_audio_channels': num_audio_channels,\n",
        "                    'hidden_size': hidden_size,\n",
        "                    'num_layers': num_layers,\n",
        "                    'bidirectional': bidirectional,\n",
        "                    'dropout': dropout,\n",
        "                    'num_sources': num_sources,\n",
        "                    'activation': activation\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        \n",
        "        # Step 2b: Define the connections between input and output.\n",
        "        # Here, the mix_magnitude key is the only input to the model.\n",
        "        connections = [\n",
        "            ['model', ['mix_magnitude']]\n",
        "        ]\n",
        "        \n",
        "        # Step 2c. The model outputs a dictionary, which SeparationModel will\n",
        "        # change the keys to model:mask, model:estimates. The lines below \n",
        "        # alias model:mask to just mask, and model:estimates to estimates.\n",
        "        # This will be important later when we actually deploy our model.\n",
        "        for key in ['mask', 'estimates']:\n",
        "            modules[key] = {'class': 'Alias'}\n",
        "            connections.append([key, f'model:{key}'])\n",
        "        \n",
        "        # Step 2d. There are two outputs from our SeparationModel: estimates and mask.\n",
        "        # Then put it all together.\n",
        "        output = ['estimates', 'mask',]\n",
        "        config = {\n",
        "            'name': cls.__name__,\n",
        "            'modules': modules,\n",
        "            'connections': connections,\n",
        "            'output': output\n",
        "        }\n",
        "        # Step 3. Instantiate the model as a SeparationModel.\n",
        "        return nussl.ml.SeparationModel(config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmIYlnWXVPC0"
      },
      "source": [
        "## Trenowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4n9jLjtVPC0"
      },
      "outputs": [],
      "source": [
        "from common import utils\n",
        "from common.models import MaskInference\n",
        "from ignite.engine import Engine\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "from ignite.engine import create_supervised_evaluator\n",
        "\n",
        "\n",
        "\n",
        "utils.logger()\n",
        "\n",
        "nf = stft_params.window_length // 2 + 1\n",
        "nac = 1\n",
        "model = MaskInference.build(nf, nac, 300, 4, True, 0.25,1, 'sigmoid')\n",
        "# model = MaskInference.build(nf, nac, 400, 5, True, 0.35,1, 'sigmoid') # testowe\n",
        "# model = nussl.ml.SeparationModel(config)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nussl.ml.train.loss.L1Loss()\n",
        "\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_data_2, num_workers=1, batch_size=10)\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_data_2, num_workers=1, batch_size=10)\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def train_step(engine, batch):\n",
        "    optimizer.zero_grad()\n",
        "    model.cuda()\n",
        "    output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )\n",
        "    \n",
        "    loss.backward() # backwards + gradient step\n",
        "    optimizer.step()\n",
        "    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(),\n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    \n",
        "    return loss_vals\n",
        "\n",
        "def val_step(engine, batch):\n",
        "    with torch.no_grad():\n",
        "        output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(), \n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    return loss_vals\n",
        "\n",
        "# Create the engines\n",
        "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
        "    train_step, val_step, device=\"cuda\"\n",
        ")\n",
        "\n",
        "# We'll save the output relative to this notebook.\n",
        "output_folder = Path('.').absolute()\n",
        "\n",
        "# Adding handlers from nussl that print out details about model training\n",
        "# run the validation step, and save the models.\n",
        "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
        "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
        "    optimizer, train_data_2, trainer, val_dataloader, validator)\n",
        "\n",
        "\n",
        "\n",
        "# trainer = Engine(print_train_data)\n",
        "    \n",
        "\n",
        "# trainer, validator = add_progress_bar_handler(trainer, validator)\n",
        "\n",
        "\n",
        "# ProgressBar().attach(trainer, output_transform=lambda x: {'batch loss': x})\n",
        "nussl.ml.train.add_progress_bar_handler(trainer,validator)\n",
        "\n",
        "trainer.run(\n",
        "    train_dataloader, \n",
        "    epoch_length=100, \n",
        "    max_epochs=30  \n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItIhBya_2Gtq"
      },
      "source": [
        "### Wczytanie modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUR_1oUd2Gtq"
      },
      "source": [
        "Ustawienie modelu po trenowaniu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SmFVaZ_2Gtq"
      },
      "outputs": [],
      "source": [
        "separator_2 = nussl.separation.deep.DeepMaskEstimation(\n",
        "    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRiAgVSO2Gtq"
      },
      "source": [
        "Pobranie modelu z repozytorium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPIqXlDB2Gtr",
        "outputId": "632b674a-c643-47c7-da6e-ce73195d5179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new/bestbest.model_vocal_11_11_e100_m40.pth\n"
          ]
        }
      ],
      "source": [
        "selected_model = [match for match in new_models_paths if \"vocal\" in match][0]\n",
        "\n",
        "print(selected_model)\n",
        "\n",
        "\n",
        "separator_2 = nussl.separation.deep.DeepMaskEstimation(\n",
        "    nussl.AudioSignal(), model_path=model_dir+selected_model,\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqbm4zsS2Gtr"
      },
      "outputs": [],
      "source": [
        "from common import viz\n",
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "item = test_data_2[30]\n",
        "\n",
        "separator_2.audio_signal = item['mix']\n",
        "estimates = separator_2()\n",
        "\n",
        "viz.show_sources(estimates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGVE1xAf2Gtr"
      },
      "outputs": [],
      "source": [
        "viz.show_sources(item['sources'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrhY8jv4VPC1"
      },
      "source": [
        "## Ocena dzialania modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUu-5XzHsrT4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "tfm = nussl_tfm.Compose([\n",
        "    nussl_tfm.SumSources([['drums', 'bass', 'other']]),\n",
        "])\n",
        "test_evaluation_dataset_2 = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SQtvZ99VPC1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "output_folder = Path('.').absolute()\n",
        "\n",
        "for i in range(50):\n",
        "    item = test_evaluation_dataset_2[i]\n",
        "    separator_2.audio_signal = item['mix']\n",
        "    estimates = separator_2()\n",
        "\n",
        "    source_keys = list(item['sources'].keys())\n",
        "    estimates = {\n",
        "        'vocals': estimates[0],\n",
        "        'drums+bass+other': item['mix'] - estimates[0]\n",
        "    }\n",
        "\n",
        "    sources = [item['sources'][k] for k in source_keys]\n",
        "    estimates = [estimates[k] for k in source_keys]\n",
        "\n",
        "    evaluator = nussl.evaluation.BSSEvalScale(\n",
        "        sources, estimates, source_labels=source_keys\n",
        "    )\n",
        "    scores = evaluator.evaluate()\n",
        "    output_folder = Path(output_folder).absolute()\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "    output_file = output_folder / sources[0].file_name.replace('wav', 'json')\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(scores, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpOM9W7AVPC2"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "json_files = glob.glob(f\"*vocals.json\")\n",
        "df2 = nussl.evaluation.aggregate_score_files(\n",
        "    json_files, aggregator=np.nanmedian)\n",
        "nussl.evaluation.associate_metrics(separator_2.model, df2, test_evaluation_dataset_2)\n",
        "report_card_2 = nussl.evaluation.report_card(\n",
        "    df2, report_each_source=True)\n",
        "print(report_card_2)\n",
        "\n",
        "filepath_2 = Path('/content/sample_data/results/vocals.csv')  \n",
        "filepath_2.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df2.to_csv(filepath_2)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCYQXYGnmEaw"
      },
      "source": [
        "# Separacja basu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-XAerodmEaw"
      },
      "outputs": [],
      "source": [
        "tfm = nussl_tfm.Compose([\n",
        "    # nussl_tfm.SumSources([['bass', 'drums', 'other']]), \n",
        "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
        "    nussl_tfm.IndexSources('source_magnitudes', 0),\n",
        "    nussl_tfm.ToSeparationModel(),\n",
        "])\n",
        "\n",
        "ps = ('uniform', -3, 3)\n",
        "ts = ('uniform', 0.6, 1.4)\n",
        "\n",
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "# Dane treningowe\n",
        "fg_path = \"~/.nussl/tutorial/train\"\n",
        "train_data_3 = data.on_the_fly(stft_params, transform=tfm, pitch_shift=ps, time_stretch=ts, fg_path=fg_path, num_mixtures=10000, coherent_prob=0.7)\n",
        "\n",
        "# Dane walidacyjne\n",
        "fg_path = \"~/.nussl/tutorial/valid\"\n",
        "val_data_3 = data.on_the_fly(stft_params, transform=tfm, pitch_shift=ps, time_stretch=ts, fg_path=fg_path, num_mixtures=200)\n",
        "\n",
        "# Dane testowe\n",
        "fg_path = \"~/.nussl/tutorial/test\"\n",
        "test_data_3 = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=100, coherent_prob=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wMbfUodmEaw"
      },
      "outputs": [],
      "source": [
        "print(test_data_3[0].keys())\n",
        "\n",
        "print(f\"Tensor shape of mix_magnitude {test_data_3[0]['mix_magnitude'].shape}\")\n",
        "print(f\"Tensor shape of source_magnitudes {test_data_3[0]['source_magnitudes'].shape}\")\n",
        "\n",
        "\n",
        "print(f\"Tensor shape of ideal binary mask {test_data_3[0]['ideal_binary_mask'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu9Bk0QVmEax"
      },
      "outputs": [],
      "source": [
        "mix_magnitude = train_data_3[0]['mix_magnitude']\n",
        "estimates = mix_magnitude.unsqueeze(-1)\n",
        "print(estimates.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wAbU-uVmEax"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BykacNfmEax"
      },
      "outputs": [],
      "source": [
        "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class MaskInference(nn.Module):\n",
        "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
        "                 num_layers, bidirectional, dropout, num_sources, \n",
        "                activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.amplitude_to_db = AmplitudeToDB()\n",
        "        self.input_normalization = BatchNorm(num_features)\n",
        "        self.recurrent_stack = RecurrentStack(\n",
        "            num_features * num_audio_channels, hidden_size, \n",
        "            num_layers, bool(bidirectional), dropout\n",
        "        )\n",
        "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
        "        self.embedding = Embedding(num_features, hidden_size, \n",
        "                                   num_sources, activation, \n",
        "                                   num_audio_channels)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        mix_magnitude = data # save for masking\n",
        "        \n",
        "        data = self.amplitude_to_db(mix_magnitude)\n",
        "        data = self.input_normalization(data)\n",
        "        data = self.recurrent_stack(data)\n",
        "        mask = self.embedding(data)\n",
        "        estimates = mix_magnitude.unsqueeze(-1) * mask\n",
        "        \n",
        "        output = {\n",
        "            'mask': mask,\n",
        "            'estimates': estimates\n",
        "        }\n",
        "        return output\n",
        "    \n",
        "    # Added function\n",
        "    @classmethod\n",
        "    def build(cls, num_features, num_audio_channels, hidden_size, \n",
        "              num_layers, bidirectional, dropout, num_sources, \n",
        "              activation='sigmoid'):\n",
        "        # Step 1. Register our model with nussl\n",
        "        nussl.ml.register_module(cls)\n",
        "        \n",
        "        # Step 2a: Define the building blocks.\n",
        "        modules = {\n",
        "            'model': {\n",
        "                'class': 'MaskInference',\n",
        "                'args': {\n",
        "                    'num_features': num_features,\n",
        "                    'num_audio_channels': num_audio_channels,\n",
        "                    'hidden_size': hidden_size,\n",
        "                    'num_layers': num_layers,\n",
        "                    'bidirectional': bidirectional,\n",
        "                    'dropout': dropout,\n",
        "                    'num_sources': num_sources,\n",
        "                    'activation': activation\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        \n",
        "        # Step 2b: Define the connections between input and output.\n",
        "        # Here, the mix_magnitude key is the only input to the model.\n",
        "        connections = [\n",
        "            ['model', ['mix_magnitude']]\n",
        "        ]\n",
        "        \n",
        "        # Step 2c. The model outputs a dictionary, which SeparationModel will\n",
        "        # change the keys to model:mask, model:estimates. The lines below \n",
        "        # alias model:mask to just mask, and model:estimates to estimates.\n",
        "        # This will be important later when we actually deploy our model.\n",
        "        for key in ['mask', 'estimates']:\n",
        "            modules[key] = {'class': 'Alias'}\n",
        "            connections.append([key, f'model:{key}'])\n",
        "        \n",
        "        # Step 2d. There are two outputs from our SeparationModel: estimates and mask.\n",
        "        # Then put it all together.\n",
        "        output = ['estimates', 'mask',]\n",
        "        config = {\n",
        "            'name': cls.__name__,\n",
        "            'modules': modules,\n",
        "            'connections': connections,\n",
        "            'output': output\n",
        "        }\n",
        "        # Step 3. Instantiate the model as a SeparationModel.\n",
        "        return nussl.ml.SeparationModel(config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvwb-gqcmEax"
      },
      "source": [
        "## Trenowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxa39e6cmEax"
      },
      "outputs": [],
      "source": [
        "from common import utils\n",
        "from common.models import MaskInference\n",
        "from ignite.engine import Engine\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "from ignite.engine import create_supervised_evaluator\n",
        "\n",
        "\n",
        "\n",
        "utils.logger()\n",
        "\n",
        "nf = stft_params.window_length // 2 + 1\n",
        "nac = 1\n",
        "# model = MaskInference.build(nf, nac, 512, 3, True, 0.25,1, 'sigmoid')\n",
        "model = MaskInference.build(nf, nac, 300, 4, True, 0.25,1, 'sigmoid')\n",
        "\n",
        "# model = nussl.ml.SeparationModel(config)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nussl.ml.train.loss.L1Loss()\n",
        "\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_data_3, num_workers=1, batch_size=10)\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_data_3, num_workers=1, batch_size=10)\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def train_step(engine, batch):\n",
        "    optimizer.zero_grad()\n",
        "    model.cuda()\n",
        "    output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )\n",
        "    \n",
        "    loss.backward() # backwards + gradient step\n",
        "    optimizer.step()\n",
        "    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(),\n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    \n",
        "    return loss_vals\n",
        "\n",
        "def val_step(engine, batch):\n",
        "    with torch.no_grad():\n",
        "        output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(), \n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    return loss_vals\n",
        "\n",
        "# Create the engines\n",
        "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
        "    train_step, val_step, device=\"cuda\"\n",
        ")\n",
        "\n",
        "# We'll save the output relative to this notebook.\n",
        "output_folder = Path('.').absolute()\n",
        "\n",
        "# Adding handlers from nussl that print out details about model training\n",
        "# run the validation step, and save the models.\n",
        "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
        "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
        "    optimizer, train_data_3, trainer, val_dataloader, validator)\n",
        "\n",
        "\n",
        "\n",
        "# trainer = Engine(print_train_data)\n",
        "\n",
        "\n",
        "# trainer, validator = add_progress_bar_handler(trainer, validator)\n",
        "\n",
        "\n",
        "# ProgressBar().attach(trainer, output_transform=lambda x: {'batch loss': x})\n",
        "nussl.ml.train.add_progress_bar_handler(trainer,validator)\n",
        "\n",
        "trainer.run(\n",
        "    train_dataloader, \n",
        "    epoch_length=100, \n",
        "    max_epochs=30  \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baSLmJTj4p_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVhgTO1d4qb3"
      },
      "source": [
        "### Wczytanie modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FadT1eqU4qb3"
      },
      "source": [
        "Ustawienie modelu po trenowaniu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdTP2Mlk4qb3"
      },
      "outputs": [],
      "source": [
        "separator_3 = nussl.separation.deep.DeepMaskEstimation(\n",
        "    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mFG-K2I4qb4"
      },
      "source": [
        "Pobranie modelu z repozytorium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP_i-fgL4qb4",
        "outputId": "68a8e4c3-6cd4-4b03-a1ec-0105c95ddb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new/bestbest.model_bass_12_11_e100_m40.pth\n"
          ]
        }
      ],
      "source": [
        "selected_model = [match for match in new_models_paths if \"bass\" in match][0]\n",
        "\n",
        "print(selected_model)\n",
        "\n",
        "\n",
        "separator_3 = nussl.separation.deep.DeepMaskEstimation(\n",
        "    nussl.AudioSignal(), model_path=model_dir+selected_model,\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUqaqu2E4qb4"
      },
      "outputs": [],
      "source": [
        "from common import viz\n",
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "item = test_data_3[32]\n",
        "separator_3.audio_signal = item['mix']\n",
        "\n",
        "estimates = separator_3()\n",
        "\n",
        "viz.show_sources(estimates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWsy0sX34qb5"
      },
      "outputs": [],
      "source": [
        "viz.show_sources(item['sources'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7GHILTMmEay"
      },
      "source": [
        "## Ocena dzialania modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvH_QoIVtsxR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "tfm = nussl_tfm.Compose([\n",
        "    nussl_tfm.SumSources([['drums', 'vocals', 'other']]),\n",
        "])\n",
        "test_evaluation_dataset_3 = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM2ud3oJmEaz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "output_folder = Path('.').absolute()\n",
        "\n",
        "for i in range(50):\n",
        "    item = test_evaluation_dataset_3[i]\n",
        "    separator_3.audio_signal = item['mix']\n",
        "    estimates = separator_3()\n",
        "\n",
        "    source_keys = list(item['sources'].keys())\n",
        "    estimates = {\n",
        "        'bass': estimates[0],\n",
        "        'drums+vocals+other': item['mix'] - estimates[0]\n",
        "    }\n",
        "\n",
        "    sources = [item['sources'][k] for k in source_keys]\n",
        "    estimates = [estimates[k] for k in source_keys]\n",
        "\n",
        "    evaluator = nussl.evaluation.BSSEvalScale(\n",
        "        sources, estimates, source_labels=source_keys\n",
        "    )\n",
        "    scores = evaluator.evaluate()\n",
        "    output_folder = Path(output_folder).absolute()\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "    output_file = output_folder / sources[0].file_name.replace('wav', 'json')\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(scores, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXfbPEIOmEaz"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "json_files = glob.glob(f\"*bass.json\")\n",
        "df3 = nussl.evaluation.aggregate_score_files(\n",
        "    json_files, aggregator=np.nanmedian)\n",
        "nussl.evaluation.associate_metrics(separator_3.model, df3, test_evaluation_dataset_3)\n",
        "report_card_3 = nussl.evaluation.report_card(\n",
        "    df3, report_each_source=True)\n",
        "print(report_card_3)\n",
        "\n",
        "filepath_3 = Path('/content/sample_data/results/bass.csv')  \n",
        "filepath_3.parent.mkdir(parents=True, exist_ok=True)  \n",
        "df3.to_csv(filepath_3)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM-T5rE4CHCt"
      },
      "source": [
        "# Wczytanie dowolnego utworu z YT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc1as66vmEay"
      },
      "outputs": [],
      "source": [
        "!pip install youtube-dl #for downloading video/audio from youtube\n",
        "\n",
        "import youtube_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23rQg456ECZc"
      },
      "source": [
        "## I utwór"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdmejpuhEACc"
      },
      "outputs": [],
      "source": [
        "ydl_args = {\n",
        "  'format' : 'bestaudio/best',\n",
        "  'outtmpl' : 'audio_sample.mp3'\n",
        "}\n",
        "\n",
        "ydl = youtube_dl.YoutubeDL(ydl_args)\n",
        "\n",
        "song_yt_link = 'https://youtu.be/aJ5IzGBnWAc?list=RDaJ5IzGBnWAc' \n",
        "\n",
        "ydl.download([song_yt_link])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxouZRAu9s3x"
      },
      "outputs": [],
      "source": [
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "\n",
        "signal_sample = nussl.AudioSignal('audio_sample.mp3')\n",
        "signal_sample.to_mono()\n",
        "signal_sample.stft(*stft_params)\n",
        "\n",
        "signal_sample.embed_audio()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_JDiXkm-Eg_"
      },
      "source": [
        "Lista modeli do separacji:\n",
        "\n",
        "\n",
        "*   separator_1 - model separujący perkusje\n",
        "*   separator_2 - moel separujący wokal\n",
        "*   separator_3 - moel separujący bas\n",
        "\n",
        "Dla utworu o długości około 4 min separacja wykonuje się 2-3 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIDB5dWZB8FP"
      },
      "outputs": [],
      "source": [
        "from common import viz\n",
        "\n",
        "separator_1.audio_signal = signal_sample\n",
        "estimates1 = separator_1()\n",
        "\n",
        "\n",
        "separator_2.audio_signal = signal_sample\n",
        "estimates2 = separator_2()\n",
        "\n",
        "\n",
        "separator_3.audio_signal = signal_sample\n",
        "estimates3 = separator_3()\n",
        "\n",
        "\n",
        "signal_sample_with_sources = {\n",
        "    'mix': signal_sample,\n",
        "    'sources':{\n",
        "        'drums': estimates1[0],\n",
        "        'vocals': estimates2[0],\n",
        "        'bass': estimates3[0]\n",
        "    }\n",
        "}\n",
        "\n",
        "viz.show_sources(signal_sample_with_sources['sources'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUtmsqKjgZCv"
      },
      "outputs": [],
      "source": [
        "nussl.play_utils.multitrack(signal_sample_with_sources['sources'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBHevGw3gZyT"
      },
      "source": [
        "## II utwór"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8McGPQUCgZyT"
      },
      "outputs": [],
      "source": [
        "ydl_args = {\n",
        "  'format' : 'bestaudio/best',\n",
        "  'outtmpl' : 'audio_sample2.mp3'\n",
        "}\n",
        "\n",
        "ydl = youtube_dl.YoutubeDL(ydl_args)\n",
        "\n",
        "song_yt_link = 'https://www.youtube.com/watch?v=d8ekz_CSBVg' \n",
        "\n",
        "ydl.download([song_yt_link])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC6A69fXgZyU"
      },
      "outputs": [],
      "source": [
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "\n",
        "signal_sample2 = nussl.AudioSignal('audio_sample2.mp3')\n",
        "signal_sample2.to_mono()\n",
        "signal_sample2.stft(*stft_params)\n",
        "\n",
        "signal_sample2.embed_audio()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLJc18nigZyU"
      },
      "source": [
        "Lista modeli do separacji:\n",
        "\n",
        "\n",
        "*   separator_1 - model separujący perkusje\n",
        "*   separator_2 - moel separujący wokal\n",
        "*   separator_3 - moel separujący bas\n",
        "\n",
        "Dla utworu o długości około 4 min separacja wykonuje się 2-3 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aQIr39DgZyU"
      },
      "outputs": [],
      "source": [
        "from common import viz\n",
        "\n",
        "separator_1.audio_signal = signal_sample2\n",
        "estimates1 = separator_1()\n",
        "\n",
        "\n",
        "separator_2.audio_signal = signal_sample2\n",
        "estimates2 = separator_2()\n",
        "\n",
        "\n",
        "separator_3.audio_signal = signal_sample2\n",
        "estimates3 = separator_3()\n",
        "\n",
        "\n",
        "signal_sample_with_sources2 = {\n",
        "    'mix': signal_sample2,\n",
        "    'sources':{\n",
        "        'drums': estimates1[0],\n",
        "        'vocals': estimates2[0],\n",
        "        'bass': estimates3[0]\n",
        "    }\n",
        "}\n",
        "\n",
        "viz.show_sources(signal_sample_with_sources2['sources'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvFP0kl4h-d1"
      },
      "outputs": [],
      "source": [
        "nussl.play_utils.multitrack(signal_sample_with_sources2['sources'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMM3dT0C4iDz"
      },
      "source": [
        "## III utwór"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeYrsCFr4iD0"
      },
      "outputs": [],
      "source": [
        "ydl_args = {\n",
        "  'format' : 'bestaudio/best',\n",
        "  'outtmpl' : 'audio_sample.mp3'\n",
        "}\n",
        "\n",
        "ydl = youtube_dl.YoutubeDL(ydl_args)\n",
        "\n",
        "song_yt_link = 'https://www.youtube.com/watch?v=w1RttxsaIBY' \n",
        "\n",
        "ydl.download([song_yt_link])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmhuBp4h4iD1"
      },
      "outputs": [],
      "source": [
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "\n",
        "signal_sample = nussl.AudioSignal('audio_sample.mp3')\n",
        "signal_sample.to_mono()\n",
        "signal_sample.stft(*stft_params)\n",
        "\n",
        "signal_sample.embed_audio()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NgpRTZI4iD1"
      },
      "source": [
        "Lista modeli do separacji:\n",
        "\n",
        "\n",
        "*   separator_1 - model separujący perkusje\n",
        "*   separator_2 - moel separujący wokal\n",
        "*   separator_3 - moel separujący bas\n",
        "\n",
        "Dla utworu o długości około 4 min separacja wykonuje się 2-3 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLsI3QhD4iD2"
      },
      "outputs": [],
      "source": [
        "from common import viz\n",
        "\n",
        "separator_1.audio_signal = signal_sample\n",
        "estimates1 = separator_1()\n",
        "\n",
        "\n",
        "separator_2.audio_signal = signal_sample\n",
        "estimates2 = separator_2()\n",
        "\n",
        "\n",
        "separator_3.audio_signal = signal_sample\n",
        "estimates3 = separator_3()\n",
        "\n",
        "\n",
        "signal_sample_with_sources = {\n",
        "    'mix': signal_sample,\n",
        "    'sources':{\n",
        "        'drums': estimates1[0],\n",
        "        'vocals': estimates2[0],\n",
        "        'bass': estimates3[0]\n",
        "    }\n",
        "}\n",
        "\n",
        "viz.show_sources(signal_sample_with_sources['sources'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZQPcZ1N4iD2"
      },
      "outputs": [],
      "source": [
        "nussl.play_utils.multitrack(signal_sample_with_sources['sources'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXGZln5k5CoH"
      },
      "source": [
        "## IV utwór"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97zG92uE5CoI",
        "outputId": "50bf3e87-9282-4f3d-ff7b-2210e6624ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] haW_ruZ_Be8: Downloading webpage\n",
            "[download] Destination: audio_sample4.mp3\n",
            "[download] 100% of 3.46MiB in 01:14\n",
            "[ffmpeg] Correcting container in \"audio_sample4.mp3\"\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ydl_args = {\n",
        "  'format' : 'bestaudio/best',\n",
        "  'outtmpl' : 'audio_sample4.mp3'\n",
        "}\n",
        "\n",
        "ydl = youtube_dl.YoutubeDL(ydl_args)\n",
        "\n",
        "song_yt_link = 'https://www.youtube.com/watch?v=haW_ruZ_Be8' \n",
        "\n",
        "ydl.download([song_yt_link])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4esgNWVA5CoI"
      },
      "outputs": [],
      "source": [
        "stft_params = nussl.STFTParams(window_length=1024, hop_length=512, window_type='sqrt_hann') \n",
        "\n",
        "\n",
        "signal_sample = nussl.AudioSignal('audio_sample4.mp3')\n",
        "signal_sample.to_mono()\n",
        "signal_sample.stft(*stft_params)\n",
        "\n",
        "signal_sample.embed_audio()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSc_YL4W5CoK"
      },
      "source": [
        "Lista modeli do separacji:\n",
        "\n",
        "\n",
        "*   separator_1 - model separujący perkusje\n",
        "*   separator_2 - moel separujący wokal\n",
        "*   separator_3 - moel separujący bas\n",
        "\n",
        "Dla utworu o długości około 4 min separacja wykonuje się 2-3 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GewJzJi5CoK"
      },
      "outputs": [],
      "source": [
        "from common import viz\n",
        "\n",
        "separator_1.audio_signal = signal_sample\n",
        "estimates1 = separator_1()\n",
        "\n",
        "\n",
        "separator_2.audio_signal = signal_sample\n",
        "estimates2 = separator_2()\n",
        "\n",
        "\n",
        "separator_3.audio_signal = signal_sample\n",
        "estimates3 = separator_3()\n",
        "\n",
        "\n",
        "signal_sample_with_sources = {\n",
        "    'mix': signal_sample,\n",
        "    'sources':{\n",
        "        'drums': estimates1[0],\n",
        "        'vocals': estimates2[0],\n",
        "        'bass': estimates3[0]\n",
        "    }\n",
        "}\n",
        "\n",
        "viz.show_sources(signal_sample_with_sources['sources'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZxziTQsz5CoL"
      },
      "outputs": [],
      "source": [
        "nussl.play_utils.multitrack(signal_sample_with_sources['sources'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}